{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the Jupyter Notebook for Project 3.\n",
    "#Within this notebook, you will find the process of data acquisition from reddit.com on two subreddit posts on two\n",
    "#supermarket chains in the USA:\n",
    "#    Kroger and Publix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "#the first url is for Kroger\n",
    "posts = []\n",
    "after = None\n",
    "headers = {'User-agent':'haha'}\n",
    "\n",
    "#range number is the number of times we wish to request for data\n",
    "#each request results in 25 posts \n",
    "for i in range(40):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        param = {}\n",
    "    else:\n",
    "        param = {'after': after}\n",
    "    url = 'https://www.reddit.com/r/kroger.json'\n",
    "    res = requests.get(url, params=param, headers=headers)\n",
    "    \n",
    "    if res.status_code == 200:\n",
    "        the_json = res.json()\n",
    "        posts.extend(the_json['data']['children'])\n",
    "        after = the_json['data']['after']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(1) \n",
    "    #intentionally slow down the loop and scraping by one sec, so that their server \n",
    "    #will not treat this as an attack and block the ip address (good for all scraping projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993\n",
      "993\n"
     ]
    }
   ],
   "source": [
    "print(len(posts))\n",
    "#checking for length of unique posts to make sure there are no repeats\n",
    "print(len(set([p['data']['name'] for p in posts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'kroger...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'kroger...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data kind\n",
       "0  {'approved_at_utc': None, 'subreddit': 'kroger...   t3\n",
       "1  {'approved_at_utc': None, 'subreddit': 'kroger...   t3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(posts)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approved_at_utc': None,\n",
       " 'subreddit': 'kroger',\n",
       " 'selftext': 'Roles will be assigned upon entering the welcome channel\\n\\n[https://discord.gg/vMAE8cF](https://discord.gg/vMAE8cF)',\n",
       " 'author_fullname': 't2_12xr6p',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': 'Welcome to Kroger Join our community Discord server',\n",
       " 'link_flair_richtext': [{'e': 'text', 't': 'News'}],\n",
       " 'subreddit_name_prefixed': 'r/kroger',\n",
       " 'hidden': False,\n",
       " 'pwls': None,\n",
       " 'link_flair_css_class': '',\n",
       " 'downs': 0,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_8s6yet',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'author_flair_background_color': '#ea0027',\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 25,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'author_flair_template_id': '2075d98a-652a-11e8-9888-0e00e9cf0e9a',\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'News',\n",
       " 'can_mod_post': False,\n",
       " 'score': 25,\n",
       " 'approved_by': None,\n",
       " 'thumbnail': '',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [{'e': 'text', 't': 'Past Employee'}],\n",
       " 'gildings': {},\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1529421937.0,\n",
       " 'link_flair_type': 'richtext',\n",
       " 'wls': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'richtext',\n",
       " 'domain': 'self.kroger',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Roles will be assigned upon entering the welcome channel&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://discord.gg/vMAE8cF\"&gt;https://discord.gg/vMAE8cF&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       " 'likes': None,\n",
       " 'suggested_sort': None,\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': True,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'all_awardings': [],\n",
       " 'media_only': False,\n",
       " 'link_flair_template_id': '2f93ab02-6eaa-11e8-aa8c-0e7af1f21342',\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': 'Past Employee',\n",
       " 'visited': False,\n",
       " 'num_reports': None,\n",
       " 'distinguished': 'moderator',\n",
       " 'subreddit_id': 't5_2svtr',\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': '8s6yet',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': 'Flava_Fraze',\n",
       " 'num_crossposts': 0,\n",
       " 'num_comments': 5,\n",
       " 'send_replies': True,\n",
       " 'whitelist_status': None,\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': 'light',\n",
       " 'permalink': '/r/kroger/comments/8s6yet/welcome_to_kroger_join_our_community_discord/',\n",
       " 'parent_whitelist_status': None,\n",
       " 'stickied': True,\n",
       " 'url': 'https://www.reddit.com/r/kroger/comments/8s6yet/welcome_to_kroger_join_our_community_discord/',\n",
       " 'subreddit_subscribers': 3660,\n",
       " 'created_utc': 1529393137.0,\n",
       " 'discussion_type': None,\n",
       " 'media': None,\n",
       " 'is_video': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking on how data looks like\n",
    "df['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Flava_Fraze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#ea0027</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'e': 'text', 't': 'Past Employee'}]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Welcome to Kroger Join our community Discord s...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>https://www.reddit.com/r/kroger/comments/8s6ye...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Xeno1337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>/r/kroger Renovation</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>https://www.reddit.com/r/kroger/comments/blu6b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments approved_at_utc approved_by  archived  \\\n",
       "0            []                False            None        None      True   \n",
       "1            []                False            None        None     False   \n",
       "\n",
       "        author author_cakeday author_flair_background_color  \\\n",
       "0  Flava_Fraze            NaN                       #ea0027   \n",
       "1     Xeno1337            NaN                          None   \n",
       "\n",
       "  author_flair_css_class                  author_flair_richtext  ...  \\\n",
       "0                   None  [{'e': 'text', 't': 'Past Employee'}]  ...   \n",
       "1                   None                                     []  ...   \n",
       "\n",
       "  thumbnail                                              title  \\\n",
       "0            Welcome to Kroger Join our community Discord s...   \n",
       "1                                         /r/kroger Renovation   \n",
       "\n",
       "  total_awards_received ups  \\\n",
       "0                     0  25   \n",
       "1                     0  23   \n",
       "\n",
       "                                                 url user_reports view_count  \\\n",
       "0  https://www.reddit.com/r/kroger/comments/8s6ye...           []       None   \n",
       "1  https://www.reddit.com/r/kroger/comments/blu6b...           []       None   \n",
       "\n",
       "  visited  whitelist_status   wls  \n",
       "0   False              None  None  \n",
       "1   False              None  None  \n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting data from json format to dataframe format\n",
    "def extract_col_as_df(df, column_name):\n",
    "    data = [i for i in df[column_name]]\n",
    "    df = pd.DataFrame(data = data)\n",
    "    return df\n",
    "\n",
    "df_k = extract_col_as_df(df, 'data')\n",
    "df_k.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kron = ['Kroger'] * df_k.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k2 = pd.DataFrame( {'text': df_k.title,\n",
    "     'target': kron,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export this df as a backup file\n",
    "df_k2.to_csv(\"df_k.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "#doing the same for publix - https://www.reddit.com/r/publix.json\n",
    "\n",
    "posts = []\n",
    "after = None\n",
    "headers = {'User-agent':'haha'}\n",
    "\n",
    "#range number is the number of times we wish to request for data\n",
    "#each request results in 25 posts \n",
    "for i in range(40):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        param = {}\n",
    "    else:\n",
    "        param = {'after': after}\n",
    "    url = 'https://www.reddit.com/r/publix.json'\n",
    "    res = requests.get(url, params=param, headers=headers)\n",
    "    \n",
    "    if res.status_code == 200:\n",
    "        the_json = res.json()\n",
    "        posts.extend(the_json['data']['children'])\n",
    "        after = the_json['data']['after']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(1) \n",
    "    #intentionally slow down the loop and scraping by one sec, so that their server \n",
    "    #will not treat this as an attack and block the ip address (good for all scraping projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "994\n"
     ]
    }
   ],
   "source": [
    "print(len(posts))\n",
    "#checking for length of unique posts to make sure there are no repeats\n",
    "print(len(set([p['data']['name'] for p in posts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'publix...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approved_at_utc': None, 'subreddit': 'publix...</td>\n",
       "      <td>t3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data kind\n",
       "0  {'approved_at_utc': None, 'subreddit': 'publix...   t3\n",
       "1  {'approved_at_utc': None, 'subreddit': 'publix...   t3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(posts)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>lexluthzor</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>The most important Publix-related website ever</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>http://arepublixchickentendersubsonsale.com/</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'is_enabled': True, 'count': 1, 'subreddit_i...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>The_Baconbitz</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>I'm just going to leave this here.</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>https://i.imgur.com/7Fmq2Xz.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       all_awardings  allow_live_comments  \\\n",
       "0                                                 []                 True   \n",
       "1  [{'is_enabled': True, 'count': 1, 'subreddit_i...                False   \n",
       "\n",
       "  approved_at_utc approved_by  archived         author  \\\n",
       "0            None        None      True     lexluthzor   \n",
       "1            None        None      True  The_Baconbitz   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                                                                         []   \n",
       "1                          None                   None                    []   \n",
       "\n",
       "  author_flair_template_id  ... thumbnail_width  \\\n",
       "0                     None  ...           140.0   \n",
       "1                     None  ...           140.0   \n",
       "\n",
       "                                            title total_awards_received  ups  \\\n",
       "0  The most important Publix-related website ever                     0  123   \n",
       "1              I'm just going to leave this here.                     1  283   \n",
       "\n",
       "                                            url user_reports view_count  \\\n",
       "0  http://arepublixchickentendersubsonsale.com/           []       None   \n",
       "1               https://i.imgur.com/7Fmq2Xz.jpg           []       None   \n",
       "\n",
       "   visited  whitelist_status   wls  \n",
       "0    False              None  None  \n",
       "1    False              None  None  \n",
       "\n",
       "[2 rows x 102 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting data from json format to dataframe format\n",
    "def extract_col_as_df(df, column_name):\n",
    "    data = [i for i in df[column_name]]\n",
    "    df = pd.DataFrame(data = data)\n",
    "    return df\n",
    "\n",
    "df_p = extract_col_as_df(df2, 'data')\n",
    "df_p.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = ['Publix'] * df_p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2 = pd.DataFrame( {'text': df_p.title,\n",
    "     'target': pub,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export this df as a backup file\n",
    "df_p2.to_csv(\"df_p.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 2)\n",
      "(994, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1987, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_k2.shape)\n",
    "print(df_p2.shape)\n",
    "\n",
    "final = df_k2.append(df_p2)\n",
    "\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Kroger Join our community Discord s...</td>\n",
       "      <td>Kroger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/r/kroger Renovation</td>\n",
       "      <td>Kroger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Welcome to Kroger Join our community Discord s...  Kroger\n",
       "1                               /r/kroger Renovation  Kroger"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the final dataframe to csv\n",
    "final.to_csv(\"final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
